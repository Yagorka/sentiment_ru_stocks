{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MessageID</th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>DateAdded</th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>IsForward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241407</td>\n",
       "      <td>1203560567</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-12 19:03:20</td>\n",
       "      <td>2023-05-12 19:02:42</td>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33684</td>\n",
       "      <td>1136626166</td>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-03 20:56:29</td>\n",
       "      <td>2023-02-03 16:46:34</td>\n",
       "      <td>Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10090</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-06-02 19:18:37</td>\n",
       "      <td>2023-06-02 18:50:00</td>\n",
       "      <td>‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10090</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-02 19:18:37</td>\n",
       "      <td>2023-06-02 18:50:00</td>\n",
       "      <td>‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9826</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-24 17:51:38</td>\n",
       "      <td>2023-04-24 13:54:00</td>\n",
       "      <td>‚Äã‚ÄãWindfall Tax ‚Äî –Ω–∞–ª–æ–≥ –Ω–∞ —Å–≤–µ—Ä—Ö–ø—Ä–∏–±—ã–ª—å. –ö–∞–∫–∏–µ ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>47482</td>\n",
       "      <td>1197210433</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-03-20 14:53:14</td>\n",
       "      <td>2023-03-20 12:15:21</td>\n",
       "      <td>#FLOT #–î–∏–≤–∏–¥–µ–Ω–¥—ã üí∞ 7% ‚Äî –≤–æ–∑–º–æ–∂–Ω–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>233829</td>\n",
       "      <td>1203560567</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-03-20 14:58:04</td>\n",
       "      <td>2023-03-20 12:05:49</td>\n",
       "      <td>üá∑üá∫#FLOT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–ò–°–¢–ê–Ø –ü–†–ò–ë–´–õ–¨ –°–û–í–ö–û–ú–§–õ–û–¢...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>9789</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-19 17:51:56</td>\n",
       "      <td>2023-04-19 15:32:00</td>\n",
       "      <td>‚Äã‚Äã–ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–Ω—Ü–∏–ø —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è  üîπ–î–∏–≤–µ—Ä—Å–∏...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>233867</td>\n",
       "      <td>1203560567</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-03-20 14:58:04</td>\n",
       "      <td>2023-03-20 14:33:32</td>\n",
       "      <td>\"üí•üá∑üá∫#PLZL #–ª–∏—Å—Ç–∏–Ω–≥ #—Ç–æ—Ä–≥–∏  \"\"–ü–æ–ª—é—Å\"\" –≤–µ–¥–µ—Ç –¥–∏–∞...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>14315</td>\n",
       "      <td>1075101206</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-07 14:56:26</td>\n",
       "      <td>2023-02-07 14:28:09</td>\n",
       "      <td>–†–æ—Å–Ω–µ—Ñ—Ç—å (ROSN) —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–∞—è —Ü–µ–Ω–∞ 425.17 —Ä—É–±–ª—è...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MessageID   ChannelID  issuerid  SentimentScore           DateAdded  \\\n",
       "0        241407  1203560567       153               2 2023-05-12 19:03:20   \n",
       "1         33684  1136626166       230               4 2023-02-03 20:56:29   \n",
       "2         10090  1063908560       118               4 2023-06-02 19:18:37   \n",
       "3         10090  1063908560       220               5 2023-06-02 19:18:37   \n",
       "4          9826  1063908560        89               2 2023-04-24 17:51:38   \n",
       "...         ...         ...       ...             ...                 ...   \n",
       "9284      47482  1197210433       157               4 2023-03-20 14:53:14   \n",
       "9285     233829  1203560567       157               4 2023-03-20 14:58:04   \n",
       "9286       9789  1063908560       225               3 2023-04-19 17:51:56   \n",
       "9287     233867  1203560567       127               3 2023-03-20 14:58:04   \n",
       "9288      14315  1075101206       112               5 2023-02-07 14:56:26   \n",
       "\n",
       "              DatePosted                                        MessageText  \\\n",
       "0    2023-05-12 19:02:42  ‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...   \n",
       "1    2023-02-03 16:46:34  Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...   \n",
       "2    2023-06-02 18:50:00  ‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...   \n",
       "3    2023-06-02 18:50:00  ‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...   \n",
       "4    2023-04-24 13:54:00  ‚Äã‚ÄãWindfall Tax ‚Äî –Ω–∞–ª–æ–≥ –Ω–∞ —Å–≤–µ—Ä—Ö–ø—Ä–∏–±—ã–ª—å. –ö–∞–∫–∏–µ ...   \n",
       "...                  ...                                                ...   \n",
       "9284 2023-03-20 12:15:21  #FLOT #–î–∏–≤–∏–¥–µ–Ω–¥—ã üí∞ 7% ‚Äî –≤–æ–∑–º–æ–∂–Ω–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç...   \n",
       "9285 2023-03-20 12:05:49  üá∑üá∫#FLOT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–ò–°–¢–ê–Ø –ü–†–ò–ë–´–õ–¨ –°–û–í–ö–û–ú–§–õ–û–¢...   \n",
       "9286 2023-04-19 15:32:00  ‚Äã‚Äã–ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–Ω—Ü–∏–ø —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è  üîπ–î–∏–≤–µ—Ä—Å–∏...   \n",
       "9287 2023-03-20 14:33:32  \"üí•üá∑üá∫#PLZL #–ª–∏—Å—Ç–∏–Ω–≥ #—Ç–æ—Ä–≥–∏  \"\"–ü–æ–ª—é—Å\"\" –≤–µ–¥–µ—Ç –¥–∏–∞...   \n",
       "9288 2023-02-07 14:28:09  –†–æ—Å–Ω–µ—Ñ—Ç—å (ROSN) —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–∞—è —Ü–µ–Ω–∞ 425.17 —Ä—É–±–ª—è...   \n",
       "\n",
       "      IsForward  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  \n",
       "...         ...  \n",
       "9284      False  \n",
       "9285      False  \n",
       "9286      False  \n",
       "9287      False  \n",
       "9288      False  \n",
       "\n",
       "[9289 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts = pd.read_pickle('/home/yagor/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/gagrin/sentiment_dataset/sentiment_texts.pickle')\n",
    "sentiment_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saved_words.pkl', 'rb') as f:\n",
    "    loaded_id_to_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flot', '—Å–æ–≤–∫–æ–º—Ñ–ª–æ—Ç', '—Ñ–ª–æ—Ç']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_id_to_names[157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_load = []\n",
    "for k, v in loaded_id_to_names.items():\n",
    "    all_words_load.extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(all_words_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sentiment_texts.loc[2, 'MessageText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u200b–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë +5.1% –í–¢–ë —Å–µ–≥–æ–¥–Ω—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—É–¥–µ—Å–∞ –Ω–∞ –≤–∏—Ä–∞–∂–∞—Ö! –í –º–æ–º–µ–Ω—Ç–µ —Ç–µ—Ä—è–ª –±–æ–ª–µ–µ 5.5% –Ω–∞ –Ω–æ–≤–æ—Å—Ç—è—Ö –æ —Ü–µ–Ω–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –¥–æ–ø—ç–º–∏—Å—Å–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–∫–∞–∑–∞–ª–∞—Å—å –ø–æ—á—Ç–∏ –Ω–∞ 15% –Ω–∏–∂–µ –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –∑–∞–∫—Ä—ã—Ç–∏—è —á–µ—Ç–≤–µ—Ä–≥–∞(—Ü–µ–Ω–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è 0,018225 —Ä—É–±–ª–µ–π). –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –ø–æ—Å–ª–µ –ø–∞–¥–µ–Ω–∏—è –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞—á–∞–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ –æ—Ç—Å–∫–∞–∫–∏–≤–∞—Ç—å –∏ –∞–∫—Ü–∏–∏ –≤—ã—à–ª–∏ –≤ –ª–∏–¥–µ—Ä—ã —Ä–æ—Å—Ç–∞üò≥  üìâ–ú–µ—á–µ–ª –∞–ø -0.5% –ï—â–µ –æ–¥–∏–Ω —Ñ–æ–∫—É—Å–Ω–∏–∫ –¥–Ω—è ‚Äî —ç—Ç–æ –ú–µ—á–µ–ª. –í –º–æ–º–µ–Ω—Ç–µ —Ç–µ—Ä—è–ª –±–æ–ª–µ–µ 5.5%, –°–î —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥—ã –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞. –ö–æ–º–ø–∞–Ω–∏—è –ø–æ–ª—É—á–∏–ª–∞ —É–±—ã—Ç–æ–∫ –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 33 258 899 —Ä—É–±–ª–µ–π 89 –∫–æ–ø–µ–µ–∫. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ, –∞–∫—Ü–∏–∏ –∫ –∫–æ–Ω—Ü—É –¥–Ω—è –≤—ã—à–ª–∏ –≤ –ø–ª—é—Åü§∑\\u200d‚ôÇÔ∏è  üìà–ú–æ—Å–±–∏—Ä–∂–∞ +4.4% –ê–∫—Ü–∏–æ–Ω–µ—Ä—ã –æ–±—Ä–∞–¥–æ–≤–∞–ª–∏—Å—å —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω–æ–º—É –¥–∏–≤–∏–¥–µ–Ω–¥—É(4.84 —Ä—É–±.). –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–¥–≤–µ–ª–∞ –∏—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤ –≤ –º–∞–µ 2023 –≥–æ–¥–∞, –æ–±—â–∏–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –Ω–∞ —Ä—ã–Ω–∫–∞—Ö –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ –≤—ã—Ä–æ—Å –Ω–∞ 20,5%üí™  üìàHMSG +31.3% üìàMDMG +6.5% –ò–¥–µ—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ —Ä–∞—Å–ø–∏—Å–∫–∞—Ö –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ü§î   üìà–†—É—Å–ì–∏–¥—Ä–æ +3.7% –°–î —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª 0,05025 —Ä—É–±–ª–µ–π –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤. –ù–µ –≥—É—Å—Ç–æ, –Ω–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º –∏ –¥–∏–≤. –ø–æ–ª–∏—Ç–∏–∫–æ–π üëè  üìà–°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç +10.5% –°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∫–µ—Ç–æ–π –ª–µ—Ç–µ—Ç—å –≤–≤–µ—Ä—Ö, –µ—â—ë —á—É—Ç—å-—á—É—Ç—å –∏ –∞–∫—Ü–∏–∏ –¥–æ–π–¥—É—Ç –¥–æ —Ü–µ–Ω—ã IPOüöÄ  üìà–ù–ú–¢–ü +3.9% üìà–î–í–ú–ü +3.7% –ü–æ—Å–ª–µ —Ä–∞–∑—Ä—ã–≤–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç–∞, —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Ä—ã–Ω–∫–∞ –Ω–∞—á–∞–ª–∏ –≤—ã–∫—É–ø–∞—Ç—å –∞–∫—Ü–∏–∏ –ø–æ—Ä—Ç–æ–≤. –ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –∂–¥—É—Ç —Å–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –ù–ú–¢–ü –∏ –î–í–ú–üüí™  üìà–†–æ—Å—Ç–µ–ª–µ–∫–æ–º +2.6% –í—ã—Ä—É—á–∫–∞ –∑–∞ 2022 –≥–æ–¥ –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ 12%, –¥–æ 650 –º–ª—Ä–¥. —Ä—É–±. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–º–Ω–æ–≥–æ, –Ω–æ –¥–ª—è —Ä–æ—Å—Ç–∞ —ç—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æüòâ   üìâ–õ—É–∫–æ–π–ª -5.4% –û—Ç–∫—Ä—ã–ª —Ç–æ—Ä–≥–∏ –ø–∞–¥–µ–Ω–∏–µ–º –±–æ–ª–µ–µ 6% –ø–æ—Å–ª–µ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–æ–π –æ—Ç—Å–µ—á–∫–∏, –ø–∞–¥–µ–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ —Å —Ä–∞–∑–º–µ—Ä–æ–º –¥–∏–≤–∏–¥–µ–Ω–¥–∞. –ü–æ–∫–∞ –∞–∫—Ü–∏–∏ –Ω–µ —Ç–æ—Ä–æ–ø—è—Ç—Å—è –∑–∞–∫—Ä—ã–≤–∞—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π –≥—ç–øüòî  üìâ–ì—Ä—É–ø–ø–∞ –ü–æ–∑–∏—Ç–∏–≤ -1.3% –ü–æ —Å–ª–æ–≤–∞–º –Æ—Ä–∏—è –ú–∞—Ä–∏–Ω–∏—á–µ–≤–∞, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ø–æ —Å–≤—è–∑—è–º —Å –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º–∏ Positive Technologies, –∫–æ–º–ø–∞–Ω–∏—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –¥–æ–ø—ç–º–∏—Å—Å–∏–∏ –∞–∫—Ü–∏–π. –û–Ω–∞ –º–æ–∂–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å—Å—è –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –∞–∫—Ü–∏–∏ —É–¥–≤–æ—è—Ç—Å—è –≤ —Ü–µ–Ω–µ. –ü—Ä–∏ —ç—Ç–æ–º —Å –º–æ–º–µ–Ω—Ç–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ü–µ–Ω–∞ —É–∂–µ –≤—ã—Ä–æ—Å–ª–∞ –≤ 2,7 —Ä–∞–∑–∞ü§î  üìàGLTR +3.6% –ë–ö–° –ú–ò –ø–∏—à–µ—Ç, —á—Ç–æ —Å—Ç–∞–≤–∫–∏ –∞—Ä–µ–Ω–¥—ã –ø–æ–ª—É–≤–∞–≥–æ–Ω–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∏ –∏ –∂–¥—É—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π —Å–≤–æ–±–æ–¥–Ω—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Ç Globaltrans. –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é ¬´–ø–æ–∫—É–ø–∞—Ç—å¬ªüßê   üìàUSDRUB +0.8% –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ –ø—Ä–æ—à–ª–∞ –Ω–æ–≤–æ—Å—Ç—å –æ —Ç–æ–º, —á—Ç–æ —Å 1 —Å–µ–Ω—Ç—è–±—Ä—è —Ä–æ—Å—Å–∏—è–Ω–µ —Å–º–æ–≥—É—Ç —Å—Ä–æ—á–Ω–æ —Å–Ω–∏–º–∞—Ç—å –Ω–µ –±–æ–ª–µ–µ 20% –≤–∫–ª–∞–¥–æ–≤ –≤ –±–∞–Ω–∫–∞—Ö –ì—Ä—É–∑–∏–∏.   –ê –º–µ–∂–¥—É —Ç–µ–º —è –≤–∞—Å –¥–∞–≤–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é, —á—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–∞–ª—é—Ç–∞ –∫–æ—Ç–æ—Ä—É—é —Å–µ–π—á–∞—Å –º–æ–∂–Ω–æ –Ω–∞–¥—ë–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å ‚Äî —ç—Ç–æ –Ω–∞–ª–∏—á–Ω–∞—è –≤–∞–ª—é—Ç–∞! –ñ–¥—É –ø–æ–¥–æ–±–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–∏ –≤–æ –≤—Å–µ—Ö –º–µ—Å—Ç–∞—Ö, –≥–¥–µ –Ω–∞—à–∏ —Å–æ–æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏ –æ—Ç–∫—Ä—ã–ª–∏ –º–Ω–æ–≥–æ –≤–∞–ª—é—Ç–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤ üòâ –í –ì—Ä—É–∑–∏–∏ —Å–¥–µ–ª–∞–ª–∏ –≤—Å—ë –ø–æ —Å–æ–≤–µ—Å—Ç–∏, –¥–æ 1 —Å–µ–Ω—Ç—è–±—Ä—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ —á—Ç–æ–±—ã –æ–±–Ω–∞–ª–∏—á–∏—Ç—å —Å–≤–æ–∏ –≤–∫–ª–∞–¥—ãüëè  –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –°–º–∞—Ä—Ç–ª–∞–±–µ: https://smart-lab.ru/blog/909238.php'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text = text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(lower_text):\n",
    "    all_ids = []\n",
    "    for k, v in loaded_id_to_names.items():\n",
    "        for name in v:\n",
    "            i = lower_text.find(name)\n",
    "            if i!=-1:\n",
    "                all_ids.append(k)\n",
    "    return list(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 99, 103, 7, 142, 111, 241, 118, 157, 185, 220, 61, 222, 223]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = text_to_ids(lower_text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_words(id, id_to_words):\n",
    "    return id_to_words[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = id_to_words(n, loaded_id_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mtlr', 'mtlrp', 'mechel', '–º–µ—á–µ–ª']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_text_with_X(text, words):\n",
    "    for i in sorted(words, key=len, reverse=True):\n",
    "        text = text.replace(i, 'X')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = text_to_text_with_X(lower_text, id_to_words(n, loaded_id_to_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = new_text.find('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X –∞–ø -0.5% –µ—â–µ –æ–¥–∏–Ω —Ñ–æ–∫—É—Å–Ω–∏–∫ –¥–Ω—è ‚Äî —ç—Ç–æ X. –≤ –º–æ–º–µ–Ω—Ç–µ —Ç–µ—Ä—è–ª –±–æ–ª–µ–µ 5.5%, —Å–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥—ã –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞. –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–ª—É—á–∏–ª–∞ —É–±—ã—Ç–æ–∫ –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 33 258 899 —Ä—É–±–ª–µ–π 89 –∫–æ–ø–µ–µ–∫. –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ, –∞–∫—Ü–∏–∏ –∫ –∫–æ–Ω—Ü—É –¥–Ω—è –≤—ã—à–ª–∏ –≤ –ø–ª—é—Åü§∑‚Äç‚ôÇÔ∏è  üìà–º–æ—Å–±–∏—Ä–∂–∞ +4.4% –∞–∫—Ü–∏–æ–Ω–µ—Ä—ã –æ–±—Ä–∞–¥–æ–≤–∞–ª–∏—Å—å —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω–æ–º—É –¥–∏–≤–∏–¥–µ–Ω–¥—É(4.84 —Ä—É–±.). –∫—Ä–æ–º–µ —Ç–æ–≥–æ, –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–¥–≤–µ–ª–∞ –∏—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤ –≤ –º–∞–µ 2023 –≥–æ–¥–∞, –æ–±—â–∏–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –Ω–∞ —Ä—ã–Ω–∫–∞—Ö –º–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ –≤—ã—Ä–æ—Å –Ω–∞ 20,5%üí™  üìàhmsg +31.3% üìàmdmg +6.5% –∏–¥–µ—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ —Ä–∞—Å–ø–∏—Å–∫–∞—Ö –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ü§î   üìà—Ä—É—Å–≥–∏–¥—Ä–æ +3.7% —Å–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª 0,05025 —Ä—É–±–ª–µ–π –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤. –Ω–µ –≥—É—Å—Ç–æ, –Ω–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º –∏ –¥–∏–≤. –ø–æ–ª–∏—Ç–∏–∫–æ–π üëè  üìà—Å–æ–≤–∫–æ–º—Ñ–ª–æ—Ç +10.5% —Å–æ–≤–∫–æ–º—Ñ–ª–æ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∫–µ—Ç–æ–π –ª–µ—Ç–µ—Ç—å –≤–≤–µ—Ä—Ö, –µ—â—ë —á—É—Ç—å-—á—É—Ç—å –∏ –∞–∫—Ü–∏–∏ –¥–æ–π–¥—É—Ç –¥–æ —Ü–µ–Ω—ã ipoüöÄ  üìà–Ω–º—Ç–ø +3.9% üìà–¥–≤–º–ø +3.7% –ø–æ—Å–ª–µ —Ä–∞–∑—Ä—ã–≤–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ —Å–æ–≤–∫–æ–º—Ñ–ª–æ—Ç–∞, —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Ä—ã–Ω–∫–∞ –Ω–∞—á–∞–ª–∏ –≤—ã–∫—É–ø–∞—Ç—å –∞–∫—Ü–∏–∏ –ø–æ—Ä—Ç–æ–≤. –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –∂–¥—É—Ç —Å–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –Ω–º—Ç–ø –∏ –¥–≤–º–øüí™  üìà—Ä–æ—Å—Ç–µ–ª–µ–∫–æ–º +2.6% –≤—ã—Ä—É—á–∫–∞ –∑–∞ 2022 –≥–æ–¥ –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ 12%, –¥–æ 650 –º–ª—Ä–¥. —Ä—É–±. –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–º–Ω–æ–≥–æ, –Ω–æ –¥–ª—è —Ä–æ—Å—Ç–∞ —ç—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æüòâ   üìâ–ª—É–∫–æ–π–ª -5.4% –æ—Ç–∫—Ä—ã–ª —Ç–æ—Ä–≥–∏ –ø–∞–¥–µ–Ω–∏–µ–º –±–æ–ª–µ–µ 6% –ø–æ—Å–ª–µ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–æ–π –æ—Ç—Å–µ—á–∫–∏, –ø–∞–¥–µ–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ —Å —Ä–∞–∑–º–µ—Ä–æ–º –¥–∏–≤–∏–¥–µ–Ω–¥–∞. –ø–æ–∫–∞ –∞–∫—Ü–∏–∏ –Ω–µ —Ç–æ—Ä–æ–ø—è—Ç—Å—è –∑–∞–∫—Ä—ã–≤–∞—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π –≥—ç–øüòî  üìâ–≥—Ä—É–ø–ø–∞ –ø–æ–∑–∏—Ç–∏–≤ -1.3% –ø–æ —Å–ª–æ–≤–∞–º —é—Ä–∏—è –º–∞—Ä–∏–Ω–∏—á–µ–≤–∞, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ø–æ —Å–≤—è–∑—è–º —Å –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º–∏ positive technologies, –∫–æ–º–ø–∞–Ω–∏—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –¥–æ–ø—ç–º–∏—Å—Å–∏–∏ –∞–∫—Ü–∏–π. –æ–Ω–∞ –º–æ–∂–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å—Å—è –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –∞–∫—Ü–∏–∏ —É–¥–≤–æ—è—Ç—Å—è –≤ —Ü–µ–Ω–µ. –ø—Ä–∏ —ç—Ç–æ–º —Å –º–æ–º–µ–Ω—Ç–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ü–µ–Ω–∞ —É–∂–µ –≤—ã—Ä–æ—Å–ª–∞ –≤ 2,7 —Ä–∞–∑–∞ü§î  üìàgltr +3.6% –±–∫—Å –º–∏ –ø–∏—à–µ—Ç, —á—Ç–æ —Å—Ç–∞–≤–∫–∏ –∞—Ä–µ–Ω–¥—ã –ø–æ–ª—É–≤–∞–≥–æ–Ω–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∏ –∏ –∂–¥—É—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π —Å–≤–æ–±–æ–¥–Ω—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Ç globaltrans. –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é ¬´–ø–æ–∫—É–ø–∞—Ç—å¬ªüßê   üìàusdrub +0.8% –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ –ø—Ä–æ—à–ª–∞ –Ω–æ–≤–æ—Å—Ç—å –æ —Ç–æ–º, —á—Ç–æ —Å 1 —Å–µ–Ω—Ç—è–±—Ä—è —Ä–æ—Å—Å–∏—è–Ω–µ —Å–º–æ–≥—É—Ç —Å—Ä–æ—á–Ω–æ —Å–Ω–∏–º–∞—Ç—å –Ω–µ –±–æ–ª–µ–µ 20% –≤–∫–ª–∞–¥–æ–≤ –≤ –±–∞–Ω–∫–∞—Ö –≥—Ä—É–∑–∏–∏.   –∞ –º–µ–∂–¥—É —Ç–µ–º —è –≤–∞—Å –¥–∞–≤–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é, —á—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–∞–ª—é—Ç–∞ –∫–æ—Ç–æ—Ä—É—é —Å–µ–π—á–∞—Å –º–æ–∂–Ω–æ –Ω–∞–¥—ë–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å ‚Äî —ç—Ç–æ –Ω–∞–ª–∏—á–Ω–∞—è –≤–∞–ª—é—Ç–∞! –∂–¥—É –ø–æ–¥–æ–±–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–∏ –≤–æ –≤—Å–µ—Ö –º–µ—Å—Ç–∞—Ö, –≥–¥–µ –Ω–∞—à–∏ —Å–æ–æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–∏ –æ—Ç–∫—Ä—ã–ª–∏ –º–Ω–æ–≥–æ –≤–∞–ª—é—Ç–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤ üòâ –≤ –≥—Ä—É–∑–∏–∏ —Å–¥–µ–ª–∞–ª–∏ –≤—Å—ë –ø–æ —Å–æ–≤–µ—Å—Ç–∏, –¥–æ 1 —Å–µ–Ω—Ç—è–±—Ä—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ —á—Ç–æ–±—ã –æ–±–Ω–∞–ª–∏—á–∏—Ç—å —Å–≤–æ–∏ –≤–∫–ª–∞–¥—ãüëè  –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ —Å–º–∞—Ä—Ç–ª–∞–±–µ: https://smart-lab.ru/blog/909238.php\n"
     ]
    }
   ],
   "source": [
    "if ind!=-1:\n",
    "    print(new_text[ind:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ–º–µ–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['‚öìÔ∏è –†–æ—Å—Å–∏–π—Å–∫–∏–µ –ø–æ—Ä—Ç–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã –ø—Ä–æ–≤–µ–ª–∏ 2022 –≥–æ–¥ –ª—É—á—à–µ –º–Ω–æ–≥–∏—Ö –¥—Ä—É–≥–∏—Ö –æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π  –ê–∫—Ü–∏–∏ –î–í–ú–ü –≤—ã—Ä–æ—Å–ª–∏ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 20% –±–ª–∞–≥–æ–¥–∞—Ä—è –ø–µ—Ä–µ–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏ —Å –ó–∞–ø–∞–¥–∞ –Ω–∞ –í–æ—Å—Ç–æ–∫. –ë—É–º–∞–≥–∏ –ù–ú–¢–ü, –Ω–∞–æ–±–æ—Ä–æ—Ç, —É–ø–∞–ª–∏ –Ω–∞ 20% –Ω–∞ —Ñ–æ–Ω–µ –∑–∞–ø–∞–¥–Ω—ã—Ö —Å–∞–Ω–∫—Ü–∏–π. –ù–æ –∏ —ç—Ç–æ –≤–¥–≤–æ–µ –º—è–≥—á–µ —Å–Ω–∏–∂–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–±–∏—Ä–∂–∏, –∫–æ—Ç–æ—Ä—ã–π –∑–∞ –≥–æ–¥ –ø–æ—Ç–µ—Ä—è–ª 40%.  –í 2023 –≥–æ–¥—É –±–∏—Ä–∂–µ–≤–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ù–ú–¢–ü –∏ –î–í–ú–ü —Å–Ω–æ–≤–∞ –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –ª—É—á—à–µ –æ–±—â–µ—Ä—ã–Ω–æ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π. –ü–æ–≤–æ–¥–æ–º –¥–ª—è —Ç–∞–∫–∏—Ö –æ–∂–∏–¥–∞–Ω–∏–π —Å—Ç–∞–ª–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ —è–Ω–≤–∞—Ä–µ.   –†–∞–∑–æ–±—Ä–∞–ª–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –¥–≤—É—Ö –∫–æ–º–ø–∞–Ω–∏–π:  https://j.tinkoff.ru/inv-tg/review-news-nmtp-fesh',\n",
       "       '–î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–µ —Å—é—Ä–ø—Ä–∏–∑—ã –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ ‚Äì —Å—Ç–æ–∏—Ç –ª–∏ –∏—Ö –æ–∂–∏–¥–∞—Ç—å?  –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –ø—Ä–∏–±–ª–∏–∂–∞–µ—Ç—Å—è —Å–µ–∑–æ–Ω –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ. –í —Å–≤–µ—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π ‚Äì —Ä–µ–∫–æ—Ä–¥–Ω—ã–µ –≤—ã–ø–ª–∞—Ç—ã –°–±–µ—Ä–∞, –º—ã —Ä–µ—à–∏–ª–∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –º–æ–≥—É—Ç –ø–æ—Ä–∞–¥–æ–≤–∞—Ç—å —Å–≤–æ–∏—Ö –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ —â–µ–¥—Ä—ã–º–∏ –≤—ã–ø–ª–∞—Ç–∞–º–∏.   –ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –≤ –∞–Ω–∞–ª–∏–∑–µ –æ–ø–∏—Ä–∞–ª–∏—Å—å –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–µ –ø–æ–ª–∏—Ç–∏–∫–∏, –∑–∞—è–≤–ª–µ–Ω–∏—è —Å–∞–º–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–π –∫–æ–º–ø–∞–Ω–∏–π –æ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞—Ö –≤—ã–ø–ª–∞—Ç.  –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, —Å—é—Ä–ø—Ä–∏–∑ ¬´–°–±–µ—Ä–∞¬ª ‚Äì —ç—Ç–æ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–µ–π—Å –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ. –ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –ø–æ–≤—ã—à–µ–Ω–Ω—ã–µ –¥–∏–≤–∏–¥–µ–Ω–¥—ã –∏–ª–∏ —Å–∞–º —Ñ–∞–∫—Ç –∏—Ö –≤—ã–ø–ª–∞—Ç —è–≤–ª—è—é—Ç—Å—è –¥–æ—Ö–æ–¥–Ω–æ–π —á–∞—Å—Ç—å—é –±—é–¥–∂–µ—Ç–∞. –ú—ã –≤—ã–¥–µ–ª–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–¥–∏–≤–∏—Ç—å –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤:   üîπ¬´–†–æ—Å–Ω–µ—Ñ—Ç—å¬ª (ROSN RX). –ö–ª—é—á–µ–≤–æ–π —Ñ–∞–∫—Ç–æ—Ä –≤—ã—Å–æ–∫–∏—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ ‚Äì –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–ø–∏—Å–∞–Ω–∏–π –∏ –æ–±–µ—Å—Ü–µ–Ω–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è–ª–∏ –Ω–∞ –ø—Ä–∏–±—ã–ª—å –≤ —Ç–µ—á–µ–Ω–∏–µ 2022 –≥., –∞ —Ç–∞–∫–∂–µ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–∞—è —Ä—ã–Ω–æ—á–Ω–∞—è –∫–æ–Ω—ä—é–Ω–∫—Ç—É—Ä–∞.  üîπ¬´–ë–∞—à–Ω–µ—Ñ—Ç—å¬ª (BANE RX). –°—É–¥—è –ø–æ –∏–º–µ—é—â–∏–º—Å—è –¥–∞–Ω–Ω—ã–º, –∫–æ–º–ø–∞–Ω–∏—è –º–æ–∂–µ—Ç —É–¥–∏–≤–∏—Ç—å –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –≤—ã—Å–æ–∫–æ–π –ø—Ä–∏–±—ã–ª—å—é –≤ 2022 –≥. –û—Ç—Å—é–¥–∞ –∏ –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ –≤—ã—Å–æ–∫–∏–º –¥–∏–≤–∏–¥–µ–Ω–¥–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—ã—á–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è –ª–µ—Ç–æ–º.   üîπ¬´–ù–ú–¢–ü¬ª (NMTP RX). –ò–¥–µ—è –ø—Ä–æ—Å—Ç–∞ ‚Äì —Ä–æ—Å—Ç –ø–µ—Ä–µ–≤–∞–ª–∫–∏ –≤ –º–æ—Ä—Å–∫–∏—Ö –ø–æ—Ä—Ç–∞—Ö –≥—Ä—É–ø–ø—ã –ø–æ–∑–∏—Ç–∏–≤–Ω–æ —Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º–∞—Ç–µ—Ä–∏–Ω—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è –≤ –ª–∏—Ü–µ ¬´–¢—Ä–∞–Ω—Å—Ñ–Ω–µ—Ñ—Ç–∏¬ª –Ω—É–∂–¥–∞–µ—Ç—Å—è, –∫–∞–∫ –∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ, –≤ —ç—Ç–∏—Ö –≤—ã–ø–ª–∞—Ç–∞—Ö.  üîπ¬´–ê–õ–†–û–°–ê¬ª (ALRS RX). –§–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∑–∞ 2021 –≥. –Ω–µ –±—ã–ª–æ, –∞ –º–µ–∂–¥—É –ø—Ä–æ—á–∏–º, –¥–∏–≤–∏–¥–µ–Ω–¥—ã ¬´–ê–õ–†–û–°–´¬ª ‚Äì —ç—Ç–æ –≤–µ—Å–æ–º–∞—è —á–∞—Å—Ç—å –¥–æ—Ö–æ–¥–æ–≤ –±—é–¥–∂–µ—Ç–∞ –Ø–∫—É—Ç–∏–∏. –°–æ–≥–ª–∞—Å–Ω–æ –∑–∞—è–≤–ª–µ–Ω–∏—è–º –≥–µ–Ω–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏ –≤ 2022 –≥. –ø—Ä–µ–≤–∑–æ—à–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑—ã.  üîπ¬´–†–æ—Å—Ç–µ–ª–µ–∫–æ–º¬ª (RTKM RX). –ö–æ–º–ø–∞–Ω–∏—è –∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞. –£—á–∏—Ç—ã–≤–∞—è –∑–∞—è–≤–ª–µ–Ω–∏—è –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞ –æ —Å–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏ –≤ 2022 –≥. –∏ –±–æ–ª–µ–µ —á–µ–º 7% –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞, –¥–∏–≤–∏–¥–µ–Ω–¥—ã –º–æ–≥—É—Ç –±—ã—Ç—å —â–µ–¥—Ä—ã–º–∏.  üîπ¬´–ò–Ω—Ç–µ—Ä –†–ê–û¬ª (IRAO RX). –≠–º–∏—Ç–µ–Ω—Ç –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ 25% –æ—Ç —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ –¥–∏–≤–∏–¥–µ–Ω–¥—ã —Ö–æ—Ç—å –∏ —è–≤–ª—è–µ—Ç—Å—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–∞—Ç—è—Ç 50%. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –±—É–¥–µ—Ç –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–∞ –≤ —Å—Ç–æ—Ä–æ–Ω—É —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤—ã–ø–ª–∞—Ç.   –°–∞–º–∞—è –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–ø–ª–∞—Ç –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –Ω–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤–æ–º —Å–µ–∫—Ç–æ—Ä–µ. –ü–æ–º–∏–º–æ –Ω–∞–∑–≤–∞–Ω–Ω—ã—Ö ¬´–†–æ—Å–Ω–µ—Ñ—Ç–∏¬ª –∏ ¬´–ë–∞—à–Ω–µ—Ñ—Ç–∏¬ª, –ø–æ–≤—ã—à–µ–Ω–Ω—ã–º–∏ –¥–∏–≤–∏–¥–µ–Ω–¥–∞–º–∏ –º–æ–≥—É—Ç –ø–æ—Ä–∞–¥–æ–≤–∞—Ç—å –∏ –¥—Ä—É–≥–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –æ—Ç—Ä–∞—Å–ª–∏ ‚Äì ¬´–ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å¬ª –∏ ¬´–¢–∞—Ç–Ω–µ—Ñ—Ç—å¬ª.   –° –Ω–∞—Ç—è–∂–∫–æ–π –º–æ–∂–µ–º —Å–∫–∞–∑–∞—Ç—å –ø—Ä–æ ¬´–ì–ê–ó–ü–†–û–ú¬ª, –Ω–æ —Å–∏—Ç—É–∞—Ü–∏—è –≤ —Å –Ω–∏–º –∏–Ω–∞—è: –ø–∞–¥–µ–Ω–∏–µ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –≤–æ 2–ü 2022 –≥. –∏ –ø–∞–¥–µ–Ω–∏–µ –∫—ç—à–∞ –Ω–∞ –±–∞–ª–∞–Ω—Å–µ.  –†–æ—Å—Å–∏–π—Å–∫–∏–µ —ç–º–∏—Ç–µ–Ω—Ç—ã –º–æ–≥—É—Ç –µ—â–µ –Ω–µ —Ä–∞–∑ –ø–æ—Ä–∞–¥–æ–≤–∞—Ç—å –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ —â–µ–¥—Ä—ã–º–∏ –≤—ã–ø–ª–∞—Ç–∞–º–∏, —Ç–µ–º –±–æ–ª–µ–µ, –±—é–¥–∂–µ—Ç –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –¥–µ–Ω–µ–∂–Ω—ã—Ö –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è—Ö. –ú—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –∫–µ–π—Å ¬´–°–±–µ—Ä–∞¬ª —è–≤–ª—è–µ—Ç—Å—è —Å–≤–æ–µ–æ–±—Ä–∞–∑–Ω—ã–º –Ω–∞—á–∞–ª–æ–º –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–æ–π –ª–∞–≤–∏–Ω—ã –Ω–∞ –æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —Ä—ã–Ω–∫–µ. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω—É—é –∫—Ä–∏—Ç–∏–∫—É, —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —É–¥–∏–≤–ª—è—Ç—å –∏ –≤ —Ö–æ—Ä–æ—à–µ–º —Å–º—ã—Å–ª–µ —Ä–∞–¥–æ–≤–∞—Ç—å.  #–¥–∏–≤–∏–¥–µ–Ω–¥—ã #—Ä–æ—Å—Å–∏–π—Å–∫–∏–π_—Ä—ã–Ω–æ–∫  @bitkogan',\n",
       "       'üí•üá∑üá∫#NMTP = +5%'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts[sentiment_texts['issuerid']==253].MessageText.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_to_words(253, loaded_id_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_id_to_names[253] = ['nmtp', '–Ω–º—Ç–ø']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts['new_text'] = sentiment_texts.apply(lambda row: text_to_text_with_X(row['MessageText'].lower(), id_to_words(row['issuerid'], loaded_id_to_names)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['‚ö†Ô∏èüá∑üá∫#X #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ X: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 2022–≥ –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å', 153],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts[['new_text', 'issuerid']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts['emdeddings'] = sentiment_texts.apply(lambda row: row['new_text'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = n%20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "5 10\n",
      "10 15\n",
      "15 20\n",
      "20 26\n",
      "26 31\n",
      "31 36\n",
      "36 41\n",
      "41 46\n",
      "46 52\n",
      "52 57\n",
      "57 62\n",
      "62 67\n",
      "67 72\n",
      "72 78\n",
      "78 83\n",
      "83 88\n",
      "88 93\n",
      "93 99\n"
     ]
    }
   ],
   "source": [
    "indexs = np.linspace(0, n, 20).astype('int')\n",
    "for i in range(s):\n",
    "    print(indexs[i], indexs[i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "model_bert = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_emb(texts, max_len_batch = 100):\n",
    "    n = len(texts)\n",
    "    s = n//max_len_batch\n",
    "    sentence_embeddings_all = None\n",
    "    # sentence_embeddings_all = torch.cat((tens_1, tens_2), 0) \n",
    "    indexs = np.linspace(0, n, s).astype('int')\n",
    "    for i in range(s-1):\n",
    "        try:\n",
    "            # print(indexs[i],indexs[i+1])\n",
    "            # print(indexs[i], indexs[i+1])\n",
    "\n",
    "            #Tokenize sentences\n",
    "\n",
    "            encoded_input = tokenizer(texts[indexs[i]:indexs[i+1]], padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "            #Compute token embeddings\n",
    "            with torch.no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "\n",
    "            #Perform pooling. In this case, mean pooling\n",
    "            sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask']).numpy()\n",
    "            if type(sentence_embeddings_all) != np.ndarray:\n",
    "                sentence_embeddings_all = sentence_embeddings.copy()\n",
    "            else:\n",
    "                sentence_embeddings_all = np.concatenate((sentence_embeddings_all, sentence_embeddings), axis=0)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        # time.sleep(3.1)\n",
    "        # print(sentence_embeddings_all.shape)\n",
    "    return sentence_embeddings_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Ñ–∏–Ω—Ç–µ—Ö-–ø—Ä–æ–¥—É–∫—Ç ¬´–¥–µ–Ω—å–≥–∏ –Ω–∞ –∑–∞–∫—É–ø–∫–∏¬ª. —Å –µ–≥–æ –ø–æ–º–æ—â—å—é –ø—Ä–æ–¥–∞–≤—Ü—ã, —Ä–∞–∑–º–µ—â–∞—é—â–∏–µ —Å–≤–æ–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ, —Å–º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –æ—Ç—Å—Ä–æ—á–∫–æ–π –ø–ª–∞—Ç–µ–∂–∞.   X –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç –∑–∞–∫—É–ø–∫—É –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞, –∞ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å –≤–Ω–æ—Å–∏—Ç –ø–ª–∞—Ç—É –ø–æ –º–µ—Ä–µ –ø–æ—è–≤–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π —Å—É–º–º—ã –Ω–∞ –±–∞–ª–∞–Ω—Å–µ –≤ —Å—Ä–æ–∫ –æ—Ç 30 –¥–æ 90 –¥–Ω–µ–π. –ø—Ä–æ–¥–∞–≤—Ü–∞–º –Ω–µ –Ω—É–∂–Ω–æ —Å–æ–±–∏—Ä–∞—Ç—å –º–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –∏—Å–∫–∞—Ç—å –ø–æ—Ä—É—á–∏—Ç–µ–ª—è ‚Äî X –ø—Ä–∏–º–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ–¥–∞–∂ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ. —Ç–∞–∫, –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª–∏ —Å–º–æ–≥—É—Ç —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –æ–±–æ—Ä–æ—Ç—ã –ø—Ä–æ–¥–∞–∂ –∏ –µ—â–µ –±—ã—Å—Ç—Ä–µ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –±–∏–∑–Ω–µ—Å.  @banksta']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentiment_texts['new_text'].values)[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(lower_text):\n",
    "    all_ids = []\n",
    "    for k, v in loaded_id_to_names.items():\n",
    "        for name in v:\n",
    "            i = lower_text.find(name)\n",
    "            if i!=-1:\n",
    "                all_ids.append(k)\n",
    "    return list(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 99, 103, 7, 142, 111, 241, 253, 118, 157, 185, 220, 61, 222, 223]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = text_to_ids(lower_text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_text_with_X(text, words):\n",
    "    for i in sorted(words, key=len, reverse=True):\n",
    "        text = text.replace(i, 'X')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = text_to_text_with_X(lower_text, id_to_words(n, loaded_id_to_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_norm = sentiment_texts[sentiment_texts['SentimentScore'].isin([1, 2, 3, 4, 5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_norm.loc[:, 'SentimentScore'] = sentiment_texts_norm.loc[:, 'SentimentScore'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_norm.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentScore\n",
       "3    3854\n",
       "2    3511\n",
       "1     944\n",
       "4     753\n",
       "0      64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts_norm.loc[:, 'SentimentScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_embeddings = texts_to_emb(list(sentiment_texts_norm['new_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = texts_embeddings, sentiment_texts_norm[['SentimentScore']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300 913 913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = np.split(sentiment_texts_norm.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(sentiment_texts_norm)), int(.9*len(sentiment_texts_norm))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = df['SentimentScore'].values\n",
    "        self.texts = [tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt') for text in df['new_text'].values]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return self.labels[idx]\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val = Dataset(df_train), Dataset(df_val)\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)\n",
    "# val_dataloader = torch.utils.data.DataLoader(val, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0][0]['token_type_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0][0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0][0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model_bert, dropout=0.3):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = model_bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.linear2 = nn.Linear(512, 5)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, out = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 730/730 [04:33<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.130                 | Train Accuracy:  0.528                 | Val Loss:  0.118                 | Val Accuracy:  0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 730/730 [04:28<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.109                 | Train Accuracy:  0.616                 | Val Loss:  0.107                 | Val Accuracy:  0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 730/730 [04:29<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.096                 | Train Accuracy:  0.674                 | Val Loss:  0.101                 | Val Accuracy:  0.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 730/730 [04:11<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.084                 | Train Accuracy:  0.716                 | Val Loss:  0.099                 | Val Accuracy:  0.616\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "model = BertClassifier(model_bert)\n",
    "LR = 1e-6\n",
    "batch_size = 10\n",
    "train(model, df_train, df_val, LR, EPOCHS, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.689\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=30)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BertClassifier(model_bert)\n",
    "model2.load_state_dict(torch.load('best_model_state.bin'))\n",
    "model2 = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.688\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=30)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model2, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = (input_ids= input_id, attention_mask=mask,return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, model_bert, dropout=0.2):\n",
    "\n",
    "        super(BertRegression, self).__init__()\n",
    "\n",
    "        self.bert = model_bert\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 512)\n",
    "        self.linear2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, out = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        out = out.last_hidden_state[:, 0, :]\n",
    "        # out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_reg(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                output = output.view(-1)\n",
    "                print(output)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "\n",
    "                # print(output.shape, train_label.shape)\n",
    "\n",
    "                output = torch.clamp(output, min=0, max=4).detach()\n",
    "                print(output.int(), train_label)\n",
    "                acc = (output.int() == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    output = output.view(-1)\n",
    "                    print(output)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    output = torch.clamp(output, min=0, max=4).detach()\n",
    "                    # output = torch.maximum(output, 0)\n",
    "                    acc = (torch.round(output).int() == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0]]).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/730 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m LR \u001b[39m=\u001b[39m \u001b[39m1e-6\u001b[39m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 5\u001b[0m train_reg(model, df_train, df_val, LR, EPOCHS, batch_size)\n",
      "Cell \u001b[0;32mIn[55], line 33\u001b[0m, in \u001b[0;36mtrain_reg\u001b[0;34m(model, train_data, val_data, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m mask \u001b[39m=\u001b[39m train_input[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m input_id \u001b[39m=\u001b[39m train_input[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 33\u001b[0m output \u001b[39m=\u001b[39m model(input_id, mask)\n\u001b[1;32m     35\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/sentim/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sentim/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[54], line 15\u001b[0m, in \u001b[0;36mBertRegression.forward\u001b[0;34m(self, input_id, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_id, mask):\n\u001b[1;32m     14\u001b[0m     _, out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(input_ids\u001b[39m=\u001b[39m input_id, attention_mask\u001b[39m=\u001b[39mmask,return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mlast_hidden_state[:, \u001b[39m0\u001b[39m, :]\n\u001b[1;32m     16\u001b[0m     \u001b[39m# out = self.dropout(out)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(out)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertRegression(model_bert)\n",
    "LR = 1e-6\n",
    "batch_size = 10\n",
    "train_reg(model, df_train, df_val, LR, EPOCHS, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m             total_acc_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m acc\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtotal_acc_test\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(test_data)\u001b[39m:\u001b[39;00m\u001b[39m .3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m evaluate(model2, df_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=30)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            output = torch.clamp(output, min=0, max=4).detach()\n",
    "\n",
    "            acc = (output.int() == test_label).sum().item()\n",
    "\n",
    "            # acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3., 53.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(torch.tensor([1.3, 3.4, 53.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.3, 3.4, 53.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3000, 3.4000, 1.0000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a>5] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "class CustomIterableDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "\n",
    "        #Store the filename in object's memory\n",
    "        self.filename = filename\n",
    "\n",
    "    def preprocess(self, text):\n",
    "\n",
    "        ### Do something with text here\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        ###\n",
    "\n",
    "        return text_pp\n",
    "\n",
    "    def line_mapper(self, line):\n",
    "        \n",
    "        #Splits the line into text and label and applies preprocessing to the text\n",
    "        text, label = line[0], line[0]\n",
    "        text = self.preprocess(text)\n",
    "\n",
    "        return text, label\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_total_num = torch.utils.data.get_worker_info().num_workers\n",
    "        worker_id = torch.utils.data.get_worker_info().id\n",
    "        #Create an iterator\n",
    "        file_itr = open(self.filename)\n",
    "\n",
    "        #Map each element using the line_mapper\n",
    "        # mapped_itr = map(self.line_mapper, file_itr)\n",
    "        \n",
    "        #Add multiworker functionality\n",
    "        # mapped_itr = itertools.islice(mapped_itr, worker_id, None, worker_total_num)\n",
    "        mapped_itr = map(self.line_mapper, itertools.islice(file_itr, worker_id, None, worker_total_num))\n",
    "\n",
    "        return mapped_itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentScore\n",
       "4                 3854\n",
       "3                 3511\n",
       "2                  944\n",
       "5                  753\n",
       "1                   64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts_norm[['SentimentScore']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9126, 1024)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9126, 1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m591.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='ovr')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36818877621408663\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/sbert_large_nlu_ru and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/sbert_large_nlu_ru\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?',\n",
    "             'X –∞–ø -0.5% –µ—â–µ –æ–¥–∏–Ω —Ñ–æ–∫—É—Å–Ω–∏–∫ –¥–Ω—è ‚Äî —ç—Ç–æ X. –≤ –º–æ–º–µ–Ω—Ç–µ —Ç–µ—Ä—è–ª –±–æ–ª–µ–µ 5.5%, —Å–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥—ã –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞. –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–ª—É—á–∏–ª–∞ —É–±—ã—Ç–æ–∫ –ø–æ –∏—Ç–æ–≥–∞–º 2022 –≥–æ–¥–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 33 258 899 —Ä—É–±–ª–µ–π 89 –∫–æ–ø–µ–µ–∫. –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ, –∞–∫—Ü–∏–∏ –∫ –∫–æ–Ω—Ü—É –¥–Ω—è –≤—ã—à–ª–∏ –≤ –ø–ª—é—Åü§∑‚Äç‚ôÇÔ∏è']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45867723, -0.25114864, -0.45541754, ...,  0.32620454,\n",
       "        -0.98523235,  0.20712802],\n",
       "       [ 1.0987989 , -0.10114849, -0.31396618, ...,  0.05905208,\n",
       "         0.72289574, -0.2861188 ],\n",
       "       [ 0.45867723, -0.25114864, -0.45541754, ...,  0.32620454,\n",
       "        -0.98523235,  0.20712802],\n",
       "       ...,\n",
       "       [ 1.0987989 , -0.10114849, -0.31396618, ...,  0.05905208,\n",
       "         0.72289574, -0.2861188 ],\n",
       "       [ 0.45867723, -0.25114864, -0.45541754, ...,  0.32620454,\n",
       "        -0.98523235,  0.20712802],\n",
       "       [ 1.0987989 , -0.10114849, -0.31396618, ...,  0.05905208,\n",
       "         0.72289574, -0.2861188 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('sentim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71b43b1161994dabcaec092bbb75f034ad127bcc84e43838e2d97cd0666f702c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
