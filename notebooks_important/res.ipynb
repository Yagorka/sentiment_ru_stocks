{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saved_words.pkl', 'rb') as f:\n",
    "    loaded_id_to_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_id_to_words(id, id_to_words):\n",
    "    return id_to_words[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(lower_text):\n",
    "    all_ids = []\n",
    "    for k, v in loaded_id_to_names.items():\n",
    "        for name in v:\n",
    "            i = lower_text.find(name)\n",
    "            if i!=-1:\n",
    "                all_ids.append(k)\n",
    "    return list(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_text_with_X(text, words):\n",
    "    for i in words:\n",
    "        text = text.replace(i, 'X')\n",
    "    # sent_text = text.split('. ')\n",
    "    # result_text = '. '.join([i for i in sent_text if 'X' in i])\n",
    "    # if len(result_text)<20:\n",
    "    #     return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\n",
    " \"​​Ключевой принцип создания портфеля  🔹Диверсификация – это скорее инвестирование в различные ценные бумаги для защиты портфеля и капитала. Мы используем разные инструменты (акции, облигации, фонды, золото), вкладываем в разные секторы экономики, в разные страны-экономики и просто в разные компании даже в рамках одной страны и одного сектора экономики.  🔹Про диверсификацию от Алексея Маркова. Это автор Хулиномики. Если не читали, то рекомендую:  «Даже беднейшим странам и беднейшим людям нужно распределять вложения — я серьёзно. Очень много финансовых проблем людей решается с помощью диверсификации. Это относится не только к богачам или к среднему классу, это относится к каждому человеку. Речь-то о рисках.   Очень часто неудача — это результат случайного события. Когда у людей начинаются реальные проблемы, которые загоняют их на днище, это почти всегда происходит из-за череды случайных событий, на которые человек не смог верно отреагировать; а правильное управление рисками может снизить удар по благополучию.» ©.  🔹Есть разные мнения поводу диверсификации. Некоторые считают, что диверсификация для слабаков. Лучше сконцентрироваться на одном активе и заработать свои иксы. При этом не забывайте, что успешных трейдеров очень немного… процента 2 или около того. И естественно вы войдете в этот процент, вы же «особенный».  🔹Другие считают, что компаний 10 в портфеле – это уже отличная диверсификация.  🔹Ну и есть крайности. Например 164 компании ( при этом часть денег заморожено в фондах, то есть диверсификация шире). Это уже нормальная диверсификация или еще нужно повышать? Думаю что надо еще повышать). И такой подход позволяет зарабатывать почти всегда.   Исключение – 2022 год, когда реализовались многие нерыночные риски. Часть замороженных фондов уже вернулись к своим значениям ( или близки к ним), которые были год назад. И это не смотря на мировые финансовые проблемы. В РФ все тоже не так плохо, многие компании стремятся к уровням, которые были до начала 24 февраля, дивиденды платятся, реинвестируются…  🔹Какие варианты распределения активов есть: — 60/40 процентов – акции/ облигации. — 80/20 — акции/ облигации. — Процент облигаций – это возраст инвестора. Остальное – акции. — Всепогодный портфель Рэя Далио. 40 процентов – долгосрочные облигации, 15 – среднесрочные облигации, 30 – акции, 7,5 — золото, 7,5 – сырьевые товары.  В последнем портфеле присутствуют различные активы и они как бы страхуют друг друга. Во время роста экономики растут акции и сырье, значит мы преимущественно докупаем облигации и золото. Во время кризиса акции падают, зато облигации позволяют нам покупать подешевевшие активы за счет купонов.  🔹Золото же стабилизирует портфель. Но в любом состоянии мы стараемся выдержать процентное соотношение. Либо что то продаем и тем самым проводит ребалансировку или просто покупаем наиболее подешевевшие активы.  🔹Есть еще Вечные портфели (напр. Тинькофф), в которых все сбалансировано. 25 процентов – акции, 25 – длинные облигации, 25 – короткие, 25 – золото. Они себя неплохо показывают в моменты кризисов, но комиссия там около 1 процента в год, что достаточно много. Но для ленивых подойдет.  🔹Можно заменить другими фондами, где комиссия ниже – Индекс Мосбиржи TMOS, Золото TGLD, Облигации TBRU и тем самым немного сэкономить.  🔹А можно попробовать составить аналогичный портфель самому, но для этого придется больше заморочиться. Если размер портфеля 100 тыс рублей, то можно купить золото на бирже – цена 5220 р, облигации – нет проблем в том, чтобы купить 50 разных штук, а вот составить портфель из российских акций на 25 тыс – это уже задача посложнее. Акция Норильского никеля – 15 900 рублей, Лукойл – 4590 р. То есть придется чем то явно жертвовать.  Спасибо за внимание, успешных инвестиций. 30-летний пенсионер Комментируйте на Смартлабе: https://smart-lab.ru/blog/896198.php\",\n",
    "\"Роснефть (ROSN) справедливая цена 425.17 рубля, потенциал роста на 23%. #сборник  1. Роснефть увеличила добычу на 3% в 2022 году, планирует увеличить ещё на 5% в 2023 https://t.me/AK47pfl/14309 2. Саудовская Аравия повышает цены реализации по нефти для всех регионов https://t.me/AK47pfl/14311 3. Нефть и газ зарабатывают много денег: BP решили увеличить инвестиции в добычу нефти https://t.me/AK47pfl/14313 4. Российская нефть проходит ограничения лучше прогнозов https://t.me/AK47pfl/14303 5. Цены реализации российской нефти, похоже, выше, чем принято считать https://t.me/AK47pfl/14304  @AK47pfl\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'сбер они и в африике сбер'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/sentim/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "model_bert = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, s, companies):\n",
    "\n",
    "        self.comp = companies\n",
    "        self.texts = [tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt') for text in s]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return self.labels[idx]\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model_bert, dropout=0.3):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = model_bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.linear2 = nn.Linear(512, 5)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, out = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, strs, companies, id_to_words):\n",
    "        self.strs = strs\n",
    "        self.companies = companies\n",
    "        self.id_to_words = id_to_words\n",
    "        self.empty_str = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(i) for i in self.companies])\n",
    "         \n",
    "    def __iter__(self):\n",
    "         # yield only valid data, skip Nones\n",
    "         for i, comp_in_str in enumerate(self.companies):\n",
    "            if len(comp_in_str)>0:\n",
    "                for j in comp_in_str:\n",
    "                    s, num_s, num_comp = text_to_text_with_X(self.strs[i], self.id_to_words[j]), i, j\n",
    "                    yield tokenizer(s, padding='max_length', truncation=True, max_length=512, return_tensors='pt'), num_s, num_comp\n",
    "            else:\n",
    "                self.empty_str.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, strs, companies, id_to_words):\n",
    "\n",
    "    test = MyDataset(strs, companies, id_to_words)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=20)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    dict_res = {}\n",
    "    res = []\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "\n",
    "        for s, num_s, num_comp in test_dataloader:\n",
    "            \n",
    "\n",
    "            mask = s['attention_mask'].to(device)\n",
    "            input_id = s['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            res = output.argmax(dim=1).detach().cpu()\n",
    "            for n_s, num_comp, sent in zip(num_s.tolist(), num_comp.tolist(), (res+1).tolist()):\n",
    "                if n_s in dict_res:\n",
    "                    dict_res[n_s].append((num_comp, float(sent)))\n",
    "                else:\n",
    "                    dict_res[n_s] = [(num_comp, float(sent))]\n",
    "    dict_res['empty'] = test.empty_str\n",
    "    return dict_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(s):\n",
    "    str_inp = False\n",
    "    if type(s) == str:\n",
    "        s = [s]\n",
    "        str_inp = True\n",
    "    s = [i.lower() for i in s]\n",
    "\n",
    "    companies =  [text_to_ids(i) for i in s]\n",
    "    print(companies)\n",
    "    result = []\n",
    "    with open('saved_words.pkl', 'rb') as f:\n",
    "        loaded_id_to_names = pickle.load(f)\n",
    "    model = BertClassifier(model_bert)\n",
    "    model.from_pretrained(\"Yagorka/sentiment_finance_ru\")#load_state_dict(torch.load('best_model_state.bin'))model = BertModel.from_pretrained(\"nielsr/my-awesome-bert-model\")\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    res = evaluate(model, s, companies, loaded_id_to_names)\n",
    "    empty_index = res['empty']\n",
    "    for i in range(len(s)):\n",
    "        if i in empty_index:\n",
    "            result.append([tuple()])\n",
    "        else:\n",
    "            result.append(res[i])             \n",
    "    return result[0] if str_inp else result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150]]\n"
     ]
    }
   ],
   "source": [
    "res = score(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(150, 3.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['трансконтейнер', 'transcontainer', 'трансконейнер', 'trcn']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_id_to_names[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('sentim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71b43b1161994dabcaec092bbb75f034ad127bcc84e43838e2d97cd0666f702c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
